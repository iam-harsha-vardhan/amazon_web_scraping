{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bdebd4-4892-465d-8ae5-436d608c2358",
   "metadata": {},
   "source": [
    "# Web Scraping from Amazon with Python\n",
    "#### This notebook demonstrates how to scrape data from Amazon's Best Sellers page in the Teaching & Education category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73519046-ee4c-4c8c-8e49-1b6073abf2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fccd7e-7956-4f4f-8750-71c6c170d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the base URL and HTTP headers\n",
    "# Base URL of the best sellers page for teaching & education books\n",
    "base_url = \"https://www.amazon.in/gp/bestsellers/books/4149461031/ref=zg_bs_pg_{}?ie=UTF8&pg={}\"\n",
    "\n",
    "# HTTP headers to mimic a browser visit\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162019ef-e7de-432b-9e2c-e8c618a3c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over pages to collect data\n",
    "# Initialize a list to store book data\n",
    "book_list = []\n",
    "\n",
    "# Iterate over the first 3 pages to get top 50 books (assuming each page has about 20 items)\n",
    "for page in range(1, 4):\n",
    "    # Construct the URL for the current page\n",
    "    url = base_url.format(page, page)\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    \n",
    "    # Find all the book elements\n",
    "    books = soup.find_all(\"div\", {\"class\": \"zg-grid-general-faceout\"})\n",
    "    \n",
    "    # Iterate over each book element to extract data\n",
    "    for book in books:\n",
    "        if len(book_list) < 50:  # Stop once we've collected 50 books\n",
    "            author = book.find(\"a\", class_=\"a-size-small a-link-child\").get_text(strip=True) if book.find(\"a\", class_=\"a-size-small a-link-child\") else \"N/A\"\n",
    "            rating = book.find(\"span\", class_=\"a-icon-alt\").get_text(strip=True) if book.find(\"span\", class_=\"a-icon-alt\") else \"N/A\"\n",
    "            \n",
    "            # Append the extracted data to the book_list\n",
    "            book_list.append({\n",
    "                \"Author\": author,\n",
    "                \"Rating\": rating\n",
    "            })\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c02082a-3150-497a-b028-9d566bef2f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Author              Rating\n",
      "0  Samapti Sinha Mahapatra  4.6 out of 5 stars\n",
      "1                      N/A  4.4 out of 5 stars\n",
      "2                 PR Yadav  4.4 out of 5 stars\n",
      "3           एम लक्ष्मीकांत  4.4 out of 5 stars\n",
      "4       Subhadra Sen Gupta  4.5 out of 5 stars\n"
     ]
    }
   ],
   "source": [
    "#Store and save the data\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df = pd.DataFrame(book_list)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"amazon_top_50_books_authors_ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ddb0b5-e67c-480e-be48-5633b6240c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Author              Rating\n",
      "18        EduGorilla Prep Experts  4.4 out of 5 stars\n",
      "43                Peter Liljedahl  4.8 out of 5 stars\n",
      "24                            N/A  4.2 out of 5 stars\n",
      "25                   Aman Kharwal  4.4 out of 5 stars\n",
      "28         ALLEN Expert Faculties  4.2 out of 5 stars\n",
      "15                   Rajesh Verma  4.3 out of 5 stars\n",
      "34  Scholastic Teaching Resources  4.6 out of 5 stars\n",
      "32        EduGorilla Prep Experts  3.9 out of 5 stars\n",
      "5               Ishinna B. Sadana  4.7 out of 5 stars\n",
      "0         Samapti Sinha Mahapatra  4.6 out of 5 stars\n"
     ]
    }
   ],
   "source": [
    "# Display a random sample of 10 rows from the DataFrame\n",
    "print(df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60d567-4167-4f22-b3de-ec01de376a57",
   "metadata": {},
   "source": [
    "Web scraping is a method for extracting data from websites by sending requests to the server, retrieving the web pages, and parsing the HTML content to obtain the desired information. This article provided an overview of how to collect data from Amazon using Python for web scraping. I hope you found this guide helpful for your data collection endeavors!\n",
    "Make sure to run each cell in order to execute the code step by step.\n",
    "You can modify the number of pages to scrape or the specific data you want to extract based on your needs.\n",
    "Always check the website's robots.txt file and terms of service to ensure that web scraping is allowed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
